{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe77eb3f",
   "metadata": {},
   "source": [
    "# **初赛的算法基础**\n",
    "\n",
    "## **Q-learing**\n",
    "\n",
    "#### **基本原理：**\n",
    "\n",
    "Q-learing算法通过不断更新$Q$值学习最优策略，$Q$值表示在某一状态下，采取某一动作能够获得的预期累计的奖励。$Q$值用于衡量当前状态下采取某个动作，最终带来的回报。Q-learing更新公式：\n",
    "\n",
    "$$Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha \\left[ r_{t+1} + \\gamma \\max_{a'} Q(s_{t+1}, a') - Q(s_t, a_t) \\right]$$\n",
    "\n",
    "其中：\n",
    "- $Q(s_t, a_t)$是当前状态$s_t$采取动作$a_t$的价值\n",
    "- $\\alpha$是学习率，控制$Q$值更新的步长\n",
    "- $r_{t+1}$是执行动作后的即时奖励\n",
    "- $s_{t+1}$是执行动作后的下一个状态\n",
    "- $\\gamma$是折扣因子，衡量当前奖励和未来奖励的重要性\n",
    "- $max_{a'}Q(s_{t+1}, a')$表示在状态$s_{t+1}$下选择的最佳动作的$Q$值\n",
    "\n",
    "传统的Q-learing中，$Q$表被用来存储每个状态-动作对的$Q$值，$Q$表是一个二维的表格，行表示状态，列表示动作。每个单元格存储了对应状态和动作的$Q$值。\n",
    "\n",
    "#### **维护$Q$表：**\n",
    "\n",
    "1. 在开始时，$Q$表中的所有$Q$值通常都被初始化为0。初始化时，agent并不知道任何状态-动作对的值。\n",
    "2. 学习过程：agent与环境交互，通过采取动作并根据反馈更新$Q$表。每次代理选择一个动作并执行后，都会根据上述公式更新对应的$Q$值。\n",
    "3. 贪婪策略：agent根据其当前的$Q$表选择动作，通常使用ε-greedy策略，即大部分时间选择当前$Q$值最大的动作，但有一定概率选择随机动作，以保证探索新状态。\n",
    "4. Q值更新：每次代理执行一个动作并获得奖励后，$Q$值会根据贝尔曼方程进行更新，以反映新的估计。随着学习的进行，$Q$表逐渐收敛，$Q$值变得更精确\n",
    "\n",
    "#### **具体示例：**\n",
    "\n",
    "假设环境为一个$5\\times 5$的格子，智能体起始位置在左上角$(0,0)$，目标位置是右下角$(4, 4)$，智能体可以选择四种动作之一：\n",
    "- Up\n",
    "- Down\n",
    "- Left\n",
    "- Right\n",
    "\n",
    "每个动作都有一个奖励：\n",
    "- 到达目标时，奖励为+10\n",
    "- 没移动一步奖励-1\n",
    "- 碰到墙壁或者超出边界，智能体停留在原地，奖励-1\n",
    "\n",
    "#### **环境与$Q$表实现**\n",
    "\n",
    "将环境状态设置为$(0,0)$到$(4,4)$的每个格子，用$(x, y)$来表示状态，并将其转换为对应的状态编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44b8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self, grid_size=5):\n",
    "        self.grid_size = grid_size\n",
    "        self.state_space = grid_size * grid_size\n",
    "        self.action_space = 4\n",
    "        self.start_state = (0, 0)\n",
    "        self.goal_state = (4, 4)\n",
    "    \n",
    "    def state_to_id(self, state):\n",
    "        return state[0] * self.grid_size + state[1]\n",
    "    \n",
    "    # 0:Up, 1:Down, 2:Left, 3:Right\n",
    "    def take_action(self, state, action):\n",
    "        x, y = state\n",
    "        if action == 0:\n",
    "            x = max(x - 1, 0)\n",
    "        elif action == 1:\n",
    "            x = min(x + 1, self.grid_size - 1)\n",
    "        elif action == 2:\n",
    "            y = max(y - 1, 0)\n",
    "        elif action == 3:\n",
    "            y = min(y + 1, self.grid_size - 1)\n",
    "        return (x, y)\n",
    "    \n",
    "    def get_reward(self, state):\n",
    "        if state == self.goal_state:\n",
    "            return 10\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.start_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7650bc",
   "metadata": {},
   "source": [
    "#### **Q-learing算法实现**\n",
    "\n",
    "1. **参数：**\n",
    "- `epsilon`：探索率决定智能体是利用已有的知识还是进行随机探索，当`epsilon`较高时，智能体更多探索未知状态，`epsilon`较低时，智能体更多利用已有知识\n",
    "- `q_table`：$Q$表是二维矩阵，用来存储每个状态-动作对应的$Q$值，`q_table[state_id, action]`存储的是从`state_id`状态下采取的`action`动作的预期回报\n",
    "\n",
    "2. **动作选择：**\n",
    "\n",
    "如果一个随机值小于当前的`epsilon`，智能体随机选择一个动作，否则智能体会选择当前状态下`Q`值最大的动作\n",
    "\n",
    "3. **$Q$值更新**\n",
    "\n",
    "- 当前$Q$值：`self.q_table[current_state_id, action]`\n",
    "- 智能体从当前状态到一下状态的预期回报：`target = reward + self.gamma * self.q_table[next_state_id, best_next_action]`，其中`self.q_table[next_state_id, best_next_action]`是下一状态的最大$Q$值\n",
    "- 当前$Q$值与目标$Q$值之间的差距：`error = target - self.q_table[current_state_id, action]`\n",
    "- $Q$值更新：self.q_table[current_state_id, action] += self.alpha * error\n",
    "\n",
    "4. **epsilon衰减**\n",
    "\n",
    "为了逐渐减少探索行为并增加利用行为，`epsilon`会随着训练的进行逐渐减少，`epsilon_decay`控制衰减速率，`min_epsilon`确保探索率不会降的过低"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4606ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/1000, Total Reward: -293, Epsilon: 0.995\n",
      "Episode 2/1000, Total Reward: -57, Epsilon: 0.990\n",
      "Episode 3/1000, Total Reward: -27, Epsilon: 0.985\n",
      "Episode 4/1000, Total Reward: -34, Epsilon: 0.980\n",
      "Episode 5/1000, Total Reward: -173, Epsilon: 0.975\n",
      "Episode 6/1000, Total Reward: -121, Epsilon: 0.970\n",
      "Episode 7/1000, Total Reward: -8, Epsilon: 0.966\n",
      "Episode 8/1000, Total Reward: -65, Epsilon: 0.961\n",
      "Episode 9/1000, Total Reward: -32, Epsilon: 0.956\n",
      "Episode 10/1000, Total Reward: -65, Epsilon: 0.951\n",
      "Episode 11/1000, Total Reward: -98, Epsilon: 0.946\n",
      "Episode 12/1000, Total Reward: -88, Epsilon: 0.942\n",
      "Episode 13/1000, Total Reward: -12, Epsilon: 0.937\n",
      "Episode 14/1000, Total Reward: -97, Epsilon: 0.932\n",
      "Episode 15/1000, Total Reward: -12, Epsilon: 0.928\n",
      "Episode 16/1000, Total Reward: -29, Epsilon: 0.923\n",
      "Episode 17/1000, Total Reward: -147, Epsilon: 0.918\n",
      "Episode 18/1000, Total Reward: -9, Epsilon: 0.914\n",
      "Episode 19/1000, Total Reward: -28, Epsilon: 0.909\n",
      "Episode 20/1000, Total Reward: -47, Epsilon: 0.905\n",
      "Episode 21/1000, Total Reward: -9, Epsilon: 0.900\n",
      "Episode 22/1000, Total Reward: -17, Epsilon: 0.896\n",
      "Episode 23/1000, Total Reward: -59, Epsilon: 0.891\n",
      "Episode 24/1000, Total Reward: -14, Epsilon: 0.887\n",
      "Episode 25/1000, Total Reward: -82, Epsilon: 0.882\n",
      "Episode 26/1000, Total Reward: -41, Epsilon: 0.878\n",
      "Episode 27/1000, Total Reward: -24, Epsilon: 0.873\n",
      "Episode 28/1000, Total Reward: -91, Epsilon: 0.869\n",
      "Episode 29/1000, Total Reward: -24, Epsilon: 0.865\n",
      "Episode 30/1000, Total Reward: -9, Epsilon: 0.860\n",
      "Episode 31/1000, Total Reward: -57, Epsilon: 0.856\n",
      "Episode 32/1000, Total Reward: -17, Epsilon: 0.852\n",
      "Episode 33/1000, Total Reward: -4, Epsilon: 0.848\n",
      "Episode 34/1000, Total Reward: -15, Epsilon: 0.843\n",
      "Episode 35/1000, Total Reward: -13, Epsilon: 0.839\n",
      "Episode 36/1000, Total Reward: 3, Epsilon: 0.835\n",
      "Episode 37/1000, Total Reward: -14, Epsilon: 0.831\n",
      "Episode 38/1000, Total Reward: -2, Epsilon: 0.827\n",
      "Episode 39/1000, Total Reward: -31, Epsilon: 0.822\n",
      "Episode 40/1000, Total Reward: -1, Epsilon: 0.818\n",
      "Episode 41/1000, Total Reward: -96, Epsilon: 0.814\n",
      "Episode 42/1000, Total Reward: -14, Epsilon: 0.810\n",
      "Episode 43/1000, Total Reward: -58, Epsilon: 0.806\n",
      "Episode 44/1000, Total Reward: -10, Epsilon: 0.802\n",
      "Episode 45/1000, Total Reward: -24, Epsilon: 0.798\n",
      "Episode 46/1000, Total Reward: -18, Epsilon: 0.794\n",
      "Episode 47/1000, Total Reward: -44, Epsilon: 0.790\n",
      "Episode 48/1000, Total Reward: -30, Epsilon: 0.786\n",
      "Episode 49/1000, Total Reward: -11, Epsilon: 0.782\n",
      "Episode 50/1000, Total Reward: -15, Epsilon: 0.778\n",
      "Episode 51/1000, Total Reward: -23, Epsilon: 0.774\n",
      "Episode 52/1000, Total Reward: -10, Epsilon: 0.771\n",
      "Episode 53/1000, Total Reward: -10, Epsilon: 0.767\n",
      "Episode 54/1000, Total Reward: -12, Epsilon: 0.763\n",
      "Episode 55/1000, Total Reward: -12, Epsilon: 0.759\n",
      "Episode 56/1000, Total Reward: -9, Epsilon: 0.755\n",
      "Episode 57/1000, Total Reward: -36, Epsilon: 0.751\n",
      "Episode 58/1000, Total Reward: -6, Epsilon: 0.748\n",
      "Episode 59/1000, Total Reward: -22, Epsilon: 0.744\n",
      "Episode 60/1000, Total Reward: 1, Epsilon: 0.740\n",
      "Episode 61/1000, Total Reward: -6, Epsilon: 0.737\n",
      "Episode 62/1000, Total Reward: -34, Epsilon: 0.733\n",
      "Episode 63/1000, Total Reward: -1, Epsilon: 0.729\n",
      "Episode 64/1000, Total Reward: -11, Epsilon: 0.726\n",
      "Episode 65/1000, Total Reward: -18, Epsilon: 0.722\n",
      "Episode 66/1000, Total Reward: -14, Epsilon: 0.718\n",
      "Episode 67/1000, Total Reward: -49, Epsilon: 0.715\n",
      "Episode 68/1000, Total Reward: -3, Epsilon: 0.711\n",
      "Episode 69/1000, Total Reward: -8, Epsilon: 0.708\n",
      "Episode 70/1000, Total Reward: -9, Epsilon: 0.704\n",
      "Episode 71/1000, Total Reward: -2, Epsilon: 0.701\n",
      "Episode 72/1000, Total Reward: -33, Epsilon: 0.697\n",
      "Episode 73/1000, Total Reward: 2, Epsilon: 0.694\n",
      "Episode 74/1000, Total Reward: 1, Epsilon: 0.690\n",
      "Episode 75/1000, Total Reward: -3, Epsilon: 0.687\n",
      "Episode 76/1000, Total Reward: -2, Epsilon: 0.683\n",
      "Episode 77/1000, Total Reward: -4, Epsilon: 0.680\n",
      "Episode 78/1000, Total Reward: -17, Epsilon: 0.676\n",
      "Episode 79/1000, Total Reward: 1, Epsilon: 0.673\n",
      "Episode 80/1000, Total Reward: -67, Epsilon: 0.670\n",
      "Episode 81/1000, Total Reward: -23, Epsilon: 0.666\n",
      "Episode 82/1000, Total Reward: -36, Epsilon: 0.663\n",
      "Episode 83/1000, Total Reward: -7, Epsilon: 0.660\n",
      "Episode 84/1000, Total Reward: -15, Epsilon: 0.656\n",
      "Episode 85/1000, Total Reward: -12, Epsilon: 0.653\n",
      "Episode 86/1000, Total Reward: -10, Epsilon: 0.650\n",
      "Episode 87/1000, Total Reward: 2, Epsilon: 0.647\n",
      "Episode 88/1000, Total Reward: -7, Epsilon: 0.643\n",
      "Episode 89/1000, Total Reward: -3, Epsilon: 0.640\n",
      "Episode 90/1000, Total Reward: -15, Epsilon: 0.637\n",
      "Episode 91/1000, Total Reward: -41, Epsilon: 0.634\n",
      "Episode 92/1000, Total Reward: -13, Epsilon: 0.631\n",
      "Episode 93/1000, Total Reward: -14, Epsilon: 0.627\n",
      "Episode 94/1000, Total Reward: -6, Epsilon: 0.624\n",
      "Episode 95/1000, Total Reward: -5, Epsilon: 0.621\n",
      "Episode 96/1000, Total Reward: 1, Epsilon: 0.618\n",
      "Episode 97/1000, Total Reward: 3, Epsilon: 0.615\n",
      "Episode 98/1000, Total Reward: -9, Epsilon: 0.612\n",
      "Episode 99/1000, Total Reward: -10, Epsilon: 0.609\n",
      "Episode 100/1000, Total Reward: -15, Epsilon: 0.606\n",
      "Episode 101/1000, Total Reward: -23, Epsilon: 0.603\n",
      "Episode 102/1000, Total Reward: 1, Epsilon: 0.600\n",
      "Episode 103/1000, Total Reward: 1, Epsilon: 0.597\n",
      "Episode 104/1000, Total Reward: -16, Epsilon: 0.594\n",
      "Episode 105/1000, Total Reward: -4, Epsilon: 0.591\n",
      "Episode 106/1000, Total Reward: 1, Epsilon: 0.588\n",
      "Episode 107/1000, Total Reward: 3, Epsilon: 0.585\n",
      "Episode 108/1000, Total Reward: -2, Epsilon: 0.582\n",
      "Episode 109/1000, Total Reward: -9, Epsilon: 0.579\n",
      "Episode 110/1000, Total Reward: -3, Epsilon: 0.576\n",
      "Episode 111/1000, Total Reward: -1, Epsilon: 0.573\n",
      "Episode 112/1000, Total Reward: -9, Epsilon: 0.570\n",
      "Episode 113/1000, Total Reward: 2, Epsilon: 0.568\n",
      "Episode 114/1000, Total Reward: -3, Epsilon: 0.565\n",
      "Episode 115/1000, Total Reward: -9, Epsilon: 0.562\n",
      "Episode 116/1000, Total Reward: 0, Epsilon: 0.559\n",
      "Episode 117/1000, Total Reward: 1, Epsilon: 0.556\n",
      "Episode 118/1000, Total Reward: -4, Epsilon: 0.554\n",
      "Episode 119/1000, Total Reward: -17, Epsilon: 0.551\n",
      "Episode 120/1000, Total Reward: -5, Epsilon: 0.548\n",
      "Episode 121/1000, Total Reward: 2, Epsilon: 0.545\n",
      "Episode 122/1000, Total Reward: -22, Epsilon: 0.543\n",
      "Episode 123/1000, Total Reward: 1, Epsilon: 0.540\n",
      "Episode 124/1000, Total Reward: -2, Epsilon: 0.537\n",
      "Episode 125/1000, Total Reward: 0, Epsilon: 0.534\n",
      "Episode 126/1000, Total Reward: -12, Epsilon: 0.532\n",
      "Episode 127/1000, Total Reward: -6, Epsilon: 0.529\n",
      "Episode 128/1000, Total Reward: -3, Epsilon: 0.526\n",
      "Episode 129/1000, Total Reward: -8, Epsilon: 0.524\n",
      "Episode 130/1000, Total Reward: -11, Epsilon: 0.521\n",
      "Episode 131/1000, Total Reward: 2, Epsilon: 0.519\n",
      "Episode 132/1000, Total Reward: -4, Epsilon: 0.516\n",
      "Episode 133/1000, Total Reward: 1, Epsilon: 0.513\n",
      "Episode 134/1000, Total Reward: -7, Epsilon: 0.511\n",
      "Episode 135/1000, Total Reward: -1, Epsilon: 0.508\n",
      "Episode 136/1000, Total Reward: 2, Epsilon: 0.506\n",
      "Episode 137/1000, Total Reward: 0, Epsilon: 0.503\n",
      "Episode 138/1000, Total Reward: -3, Epsilon: 0.501\n",
      "Episode 139/1000, Total Reward: -5, Epsilon: 0.498\n",
      "Episode 140/1000, Total Reward: -3, Epsilon: 0.496\n",
      "Episode 141/1000, Total Reward: -13, Epsilon: 0.493\n",
      "Episode 142/1000, Total Reward: 0, Epsilon: 0.491\n",
      "Episode 143/1000, Total Reward: 3, Epsilon: 0.488\n",
      "Episode 144/1000, Total Reward: 1, Epsilon: 0.486\n",
      "Episode 145/1000, Total Reward: 3, Epsilon: 0.483\n",
      "Episode 146/1000, Total Reward: 3, Epsilon: 0.481\n",
      "Episode 147/1000, Total Reward: -2, Epsilon: 0.479\n",
      "Episode 148/1000, Total Reward: 3, Epsilon: 0.476\n",
      "Episode 149/1000, Total Reward: 1, Epsilon: 0.474\n",
      "Episode 150/1000, Total Reward: -32, Epsilon: 0.471\n",
      "Episode 151/1000, Total Reward: -17, Epsilon: 0.469\n",
      "Episode 152/1000, Total Reward: -6, Epsilon: 0.467\n",
      "Episode 153/1000, Total Reward: 0, Epsilon: 0.464\n",
      "Episode 154/1000, Total Reward: -9, Epsilon: 0.462\n",
      "Episode 155/1000, Total Reward: -13, Epsilon: 0.460\n",
      "Episode 156/1000, Total Reward: -1, Epsilon: 0.458\n",
      "Episode 157/1000, Total Reward: -9, Epsilon: 0.455\n",
      "Episode 158/1000, Total Reward: -1, Epsilon: 0.453\n",
      "Episode 159/1000, Total Reward: 3, Epsilon: 0.451\n",
      "Episode 160/1000, Total Reward: 1, Epsilon: 0.448\n",
      "Episode 161/1000, Total Reward: 3, Epsilon: 0.446\n",
      "Episode 162/1000, Total Reward: -22, Epsilon: 0.444\n",
      "Episode 163/1000, Total Reward: -4, Epsilon: 0.442\n",
      "Episode 164/1000, Total Reward: -9, Epsilon: 0.440\n",
      "Episode 165/1000, Total Reward: -1, Epsilon: 0.437\n",
      "Episode 166/1000, Total Reward: -6, Epsilon: 0.435\n",
      "Episode 167/1000, Total Reward: -18, Epsilon: 0.433\n",
      "Episode 168/1000, Total Reward: 2, Epsilon: 0.431\n",
      "Episode 169/1000, Total Reward: -5, Epsilon: 0.429\n",
      "Episode 170/1000, Total Reward: -2, Epsilon: 0.427\n",
      "Episode 171/1000, Total Reward: -8, Epsilon: 0.424\n",
      "Episode 172/1000, Total Reward: 1, Epsilon: 0.422\n",
      "Episode 173/1000, Total Reward: -1, Epsilon: 0.420\n",
      "Episode 174/1000, Total Reward: 0, Epsilon: 0.418\n",
      "Episode 175/1000, Total Reward: -4, Epsilon: 0.416\n",
      "Episode 176/1000, Total Reward: -7, Epsilon: 0.414\n",
      "Episode 177/1000, Total Reward: 1, Epsilon: 0.412\n",
      "Episode 178/1000, Total Reward: 3, Epsilon: 0.410\n",
      "Episode 179/1000, Total Reward: 2, Epsilon: 0.408\n",
      "Episode 180/1000, Total Reward: -1, Epsilon: 0.406\n",
      "Episode 181/1000, Total Reward: 3, Epsilon: 0.404\n",
      "Episode 182/1000, Total Reward: -7, Epsilon: 0.402\n",
      "Episode 183/1000, Total Reward: 2, Epsilon: 0.400\n",
      "Episode 184/1000, Total Reward: -1, Epsilon: 0.398\n",
      "Episode 185/1000, Total Reward: -13, Epsilon: 0.396\n",
      "Episode 186/1000, Total Reward: 0, Epsilon: 0.394\n",
      "Episode 187/1000, Total Reward: 0, Epsilon: 0.392\n",
      "Episode 188/1000, Total Reward: -6, Epsilon: 0.390\n",
      "Episode 189/1000, Total Reward: 0, Epsilon: 0.388\n",
      "Episode 190/1000, Total Reward: -1, Epsilon: 0.386\n",
      "Episode 191/1000, Total Reward: 3, Epsilon: 0.384\n",
      "Episode 192/1000, Total Reward: -1, Epsilon: 0.382\n",
      "Episode 193/1000, Total Reward: 2, Epsilon: 0.380\n",
      "Episode 194/1000, Total Reward: -9, Epsilon: 0.378\n",
      "Episode 195/1000, Total Reward: -1, Epsilon: 0.376\n",
      "Episode 196/1000, Total Reward: -2, Epsilon: 0.374\n",
      "Episode 197/1000, Total Reward: 1, Epsilon: 0.373\n",
      "Episode 198/1000, Total Reward: -5, Epsilon: 0.371\n",
      "Episode 199/1000, Total Reward: -16, Epsilon: 0.369\n",
      "Episode 200/1000, Total Reward: -1, Epsilon: 0.367\n",
      "Episode 201/1000, Total Reward: 1, Epsilon: 0.365\n",
      "Episode 202/1000, Total Reward: -2, Epsilon: 0.363\n",
      "Episode 203/1000, Total Reward: -1, Epsilon: 0.361\n",
      "Episode 204/1000, Total Reward: 3, Epsilon: 0.360\n",
      "Episode 205/1000, Total Reward: 3, Epsilon: 0.358\n",
      "Episode 206/1000, Total Reward: -1, Epsilon: 0.356\n",
      "Episode 207/1000, Total Reward: 3, Epsilon: 0.354\n",
      "Episode 208/1000, Total Reward: 0, Epsilon: 0.353\n",
      "Episode 209/1000, Total Reward: 2, Epsilon: 0.351\n",
      "Episode 210/1000, Total Reward: 3, Epsilon: 0.349\n",
      "Episode 211/1000, Total Reward: 1, Epsilon: 0.347\n",
      "Episode 212/1000, Total Reward: -4, Epsilon: 0.346\n",
      "Episode 213/1000, Total Reward: 3, Epsilon: 0.344\n",
      "Episode 214/1000, Total Reward: -1, Epsilon: 0.342\n",
      "Episode 215/1000, Total Reward: 3, Epsilon: 0.340\n",
      "Episode 216/1000, Total Reward: 3, Epsilon: 0.339\n",
      "Episode 217/1000, Total Reward: -1, Epsilon: 0.337\n",
      "Episode 218/1000, Total Reward: -14, Epsilon: 0.335\n",
      "Episode 219/1000, Total Reward: 0, Epsilon: 0.334\n",
      "Episode 220/1000, Total Reward: 2, Epsilon: 0.332\n",
      "Episode 221/1000, Total Reward: -4, Epsilon: 0.330\n",
      "Episode 222/1000, Total Reward: 0, Epsilon: 0.329\n",
      "Episode 223/1000, Total Reward: 2, Epsilon: 0.327\n",
      "Episode 224/1000, Total Reward: -10, Epsilon: 0.325\n",
      "Episode 225/1000, Total Reward: 3, Epsilon: 0.324\n",
      "Episode 226/1000, Total Reward: 3, Epsilon: 0.322\n",
      "Episode 227/1000, Total Reward: 1, Epsilon: 0.321\n",
      "Episode 228/1000, Total Reward: -1, Epsilon: 0.319\n",
      "Episode 229/1000, Total Reward: -4, Epsilon: 0.317\n",
      "Episode 230/1000, Total Reward: -1, Epsilon: 0.316\n",
      "Episode 231/1000, Total Reward: -4, Epsilon: 0.314\n",
      "Episode 232/1000, Total Reward: -2, Epsilon: 0.313\n",
      "Episode 233/1000, Total Reward: -7, Epsilon: 0.311\n",
      "Episode 234/1000, Total Reward: 2, Epsilon: 0.309\n",
      "Episode 235/1000, Total Reward: 1, Epsilon: 0.308\n",
      "Episode 236/1000, Total Reward: -1, Epsilon: 0.306\n",
      "Episode 237/1000, Total Reward: -2, Epsilon: 0.305\n",
      "Episode 238/1000, Total Reward: -14, Epsilon: 0.303\n",
      "Episode 239/1000, Total Reward: 1, Epsilon: 0.302\n",
      "Episode 240/1000, Total Reward: 3, Epsilon: 0.300\n",
      "Episode 241/1000, Total Reward: 1, Epsilon: 0.299\n",
      "Episode 242/1000, Total Reward: 1, Epsilon: 0.297\n",
      "Episode 243/1000, Total Reward: 3, Epsilon: 0.296\n",
      "Episode 244/1000, Total Reward: -2, Epsilon: 0.294\n",
      "Episode 245/1000, Total Reward: 1, Epsilon: 0.293\n",
      "Episode 246/1000, Total Reward: 3, Epsilon: 0.291\n",
      "Episode 247/1000, Total Reward: 3, Epsilon: 0.290\n",
      "Episode 248/1000, Total Reward: 1, Epsilon: 0.288\n",
      "Episode 249/1000, Total Reward: -1, Epsilon: 0.287\n",
      "Episode 250/1000, Total Reward: 1, Epsilon: 0.286\n",
      "Episode 251/1000, Total Reward: -2, Epsilon: 0.284\n",
      "Episode 252/1000, Total Reward: 3, Epsilon: 0.283\n",
      "Episode 253/1000, Total Reward: 1, Epsilon: 0.281\n",
      "Episode 254/1000, Total Reward: 3, Epsilon: 0.280\n",
      "Episode 255/1000, Total Reward: 0, Epsilon: 0.279\n",
      "Episode 256/1000, Total Reward: 1, Epsilon: 0.277\n",
      "Episode 257/1000, Total Reward: -1, Epsilon: 0.276\n",
      "Episode 258/1000, Total Reward: 1, Epsilon: 0.274\n",
      "Episode 259/1000, Total Reward: -5, Epsilon: 0.273\n",
      "Episode 260/1000, Total Reward: -2, Epsilon: 0.272\n",
      "Episode 261/1000, Total Reward: 1, Epsilon: 0.270\n",
      "Episode 262/1000, Total Reward: 1, Epsilon: 0.269\n",
      "Episode 263/1000, Total Reward: -11, Epsilon: 0.268\n",
      "Episode 264/1000, Total Reward: 0, Epsilon: 0.266\n",
      "Episode 265/1000, Total Reward: -1, Epsilon: 0.265\n",
      "Episode 266/1000, Total Reward: -1, Epsilon: 0.264\n",
      "Episode 267/1000, Total Reward: 1, Epsilon: 0.262\n",
      "Episode 268/1000, Total Reward: 0, Epsilon: 0.261\n",
      "Episode 269/1000, Total Reward: 3, Epsilon: 0.260\n",
      "Episode 270/1000, Total Reward: -1, Epsilon: 0.258\n",
      "Episode 271/1000, Total Reward: 3, Epsilon: 0.257\n",
      "Episode 272/1000, Total Reward: 1, Epsilon: 0.256\n",
      "Episode 273/1000, Total Reward: 3, Epsilon: 0.255\n",
      "Episode 274/1000, Total Reward: 1, Epsilon: 0.253\n",
      "Episode 275/1000, Total Reward: 3, Epsilon: 0.252\n",
      "Episode 276/1000, Total Reward: 3, Epsilon: 0.251\n",
      "Episode 277/1000, Total Reward: -3, Epsilon: 0.249\n",
      "Episode 278/1000, Total Reward: 3, Epsilon: 0.248\n",
      "Episode 279/1000, Total Reward: -2, Epsilon: 0.247\n",
      "Episode 280/1000, Total Reward: 3, Epsilon: 0.246\n",
      "Episode 281/1000, Total Reward: -3, Epsilon: 0.245\n",
      "Episode 282/1000, Total Reward: -3, Epsilon: 0.243\n",
      "Episode 283/1000, Total Reward: 1, Epsilon: 0.242\n",
      "Episode 284/1000, Total Reward: 1, Epsilon: 0.241\n",
      "Episode 285/1000, Total Reward: -5, Epsilon: 0.240\n",
      "Episode 286/1000, Total Reward: -4, Epsilon: 0.238\n",
      "Episode 287/1000, Total Reward: -5, Epsilon: 0.237\n",
      "Episode 288/1000, Total Reward: -4, Epsilon: 0.236\n",
      "Episode 289/1000, Total Reward: 3, Epsilon: 0.235\n",
      "Episode 290/1000, Total Reward: 0, Epsilon: 0.234\n",
      "Episode 291/1000, Total Reward: 1, Epsilon: 0.233\n",
      "Episode 292/1000, Total Reward: 0, Epsilon: 0.231\n",
      "Episode 293/1000, Total Reward: 3, Epsilon: 0.230\n",
      "Episode 294/1000, Total Reward: -7, Epsilon: 0.229\n",
      "Episode 295/1000, Total Reward: 1, Epsilon: 0.228\n",
      "Episode 296/1000, Total Reward: 3, Epsilon: 0.227\n",
      "Episode 297/1000, Total Reward: 3, Epsilon: 0.226\n",
      "Episode 298/1000, Total Reward: -1, Epsilon: 0.225\n",
      "Episode 299/1000, Total Reward: 3, Epsilon: 0.223\n",
      "Episode 300/1000, Total Reward: 1, Epsilon: 0.222\n",
      "Episode 301/1000, Total Reward: -2, Epsilon: 0.221\n",
      "Episode 302/1000, Total Reward: -1, Epsilon: 0.220\n",
      "Episode 303/1000, Total Reward: 1, Epsilon: 0.219\n",
      "Episode 304/1000, Total Reward: 1, Epsilon: 0.218\n",
      "Episode 305/1000, Total Reward: 3, Epsilon: 0.217\n",
      "Episode 306/1000, Total Reward: 1, Epsilon: 0.216\n",
      "Episode 307/1000, Total Reward: -2, Epsilon: 0.215\n",
      "Episode 308/1000, Total Reward: 3, Epsilon: 0.214\n",
      "Episode 309/1000, Total Reward: 1, Epsilon: 0.212\n",
      "Episode 310/1000, Total Reward: 3, Epsilon: 0.211\n",
      "Episode 311/1000, Total Reward: 3, Epsilon: 0.210\n",
      "Episode 312/1000, Total Reward: 3, Epsilon: 0.209\n",
      "Episode 313/1000, Total Reward: 3, Epsilon: 0.208\n",
      "Episode 314/1000, Total Reward: 2, Epsilon: 0.207\n",
      "Episode 315/1000, Total Reward: 1, Epsilon: 0.206\n",
      "Episode 316/1000, Total Reward: -3, Epsilon: 0.205\n",
      "Episode 317/1000, Total Reward: 3, Epsilon: 0.204\n",
      "Episode 318/1000, Total Reward: 2, Epsilon: 0.203\n",
      "Episode 319/1000, Total Reward: 2, Epsilon: 0.202\n",
      "Episode 320/1000, Total Reward: 3, Epsilon: 0.201\n",
      "Episode 321/1000, Total Reward: 3, Epsilon: 0.200\n",
      "Episode 322/1000, Total Reward: 0, Epsilon: 0.199\n",
      "Episode 323/1000, Total Reward: 1, Epsilon: 0.198\n",
      "Episode 324/1000, Total Reward: 1, Epsilon: 0.197\n",
      "Episode 325/1000, Total Reward: 1, Epsilon: 0.196\n",
      "Episode 326/1000, Total Reward: 0, Epsilon: 0.195\n",
      "Episode 327/1000, Total Reward: 3, Epsilon: 0.194\n",
      "Episode 328/1000, Total Reward: -1, Epsilon: 0.193\n",
      "Episode 329/1000, Total Reward: -3, Epsilon: 0.192\n",
      "Episode 330/1000, Total Reward: 3, Epsilon: 0.191\n",
      "Episode 331/1000, Total Reward: 3, Epsilon: 0.190\n",
      "Episode 332/1000, Total Reward: 3, Epsilon: 0.189\n",
      "Episode 333/1000, Total Reward: -3, Epsilon: 0.188\n",
      "Episode 334/1000, Total Reward: 1, Epsilon: 0.187\n",
      "Episode 335/1000, Total Reward: 1, Epsilon: 0.187\n",
      "Episode 336/1000, Total Reward: -1, Epsilon: 0.186\n",
      "Episode 337/1000, Total Reward: 1, Epsilon: 0.185\n",
      "Episode 338/1000, Total Reward: 3, Epsilon: 0.184\n",
      "Episode 339/1000, Total Reward: 2, Epsilon: 0.183\n",
      "Episode 340/1000, Total Reward: 0, Epsilon: 0.182\n",
      "Episode 341/1000, Total Reward: 3, Epsilon: 0.181\n",
      "Episode 342/1000, Total Reward: -6, Epsilon: 0.180\n",
      "Episode 343/1000, Total Reward: 3, Epsilon: 0.179\n",
      "Episode 344/1000, Total Reward: 1, Epsilon: 0.178\n",
      "Episode 345/1000, Total Reward: 3, Epsilon: 0.177\n",
      "Episode 346/1000, Total Reward: 0, Epsilon: 0.177\n",
      "Episode 347/1000, Total Reward: -1, Epsilon: 0.176\n",
      "Episode 348/1000, Total Reward: -3, Epsilon: 0.175\n",
      "Episode 349/1000, Total Reward: 1, Epsilon: 0.174\n",
      "Episode 350/1000, Total Reward: 2, Epsilon: 0.173\n",
      "Episode 351/1000, Total Reward: 1, Epsilon: 0.172\n",
      "Episode 352/1000, Total Reward: -2, Epsilon: 0.171\n",
      "Episode 353/1000, Total Reward: -1, Epsilon: 0.170\n",
      "Episode 354/1000, Total Reward: 3, Epsilon: 0.170\n",
      "Episode 355/1000, Total Reward: 2, Epsilon: 0.169\n",
      "Episode 356/1000, Total Reward: 1, Epsilon: 0.168\n",
      "Episode 357/1000, Total Reward: 2, Epsilon: 0.167\n",
      "Episode 358/1000, Total Reward: 3, Epsilon: 0.166\n",
      "Episode 359/1000, Total Reward: -1, Epsilon: 0.165\n",
      "Episode 360/1000, Total Reward: 3, Epsilon: 0.165\n",
      "Episode 361/1000, Total Reward: 3, Epsilon: 0.164\n",
      "Episode 362/1000, Total Reward: 2, Epsilon: 0.163\n",
      "Episode 363/1000, Total Reward: 3, Epsilon: 0.162\n",
      "Episode 364/1000, Total Reward: -1, Epsilon: 0.161\n",
      "Episode 365/1000, Total Reward: -1, Epsilon: 0.160\n",
      "Episode 366/1000, Total Reward: 3, Epsilon: 0.160\n",
      "Episode 367/1000, Total Reward: 3, Epsilon: 0.159\n",
      "Episode 368/1000, Total Reward: 1, Epsilon: 0.158\n",
      "Episode 369/1000, Total Reward: 1, Epsilon: 0.157\n",
      "Episode 370/1000, Total Reward: -5, Epsilon: 0.157\n",
      "Episode 371/1000, Total Reward: 1, Epsilon: 0.156\n",
      "Episode 372/1000, Total Reward: 3, Epsilon: 0.155\n",
      "Episode 373/1000, Total Reward: -3, Epsilon: 0.154\n",
      "Episode 374/1000, Total Reward: -1, Epsilon: 0.153\n",
      "Episode 375/1000, Total Reward: 3, Epsilon: 0.153\n",
      "Episode 376/1000, Total Reward: 1, Epsilon: 0.152\n",
      "Episode 377/1000, Total Reward: 1, Epsilon: 0.151\n",
      "Episode 378/1000, Total Reward: 3, Epsilon: 0.150\n",
      "Episode 379/1000, Total Reward: 3, Epsilon: 0.150\n",
      "Episode 380/1000, Total Reward: 3, Epsilon: 0.149\n",
      "Episode 381/1000, Total Reward: 3, Epsilon: 0.148\n",
      "Episode 382/1000, Total Reward: -3, Epsilon: 0.147\n",
      "Episode 383/1000, Total Reward: 3, Epsilon: 0.147\n",
      "Episode 384/1000, Total Reward: 3, Epsilon: 0.146\n",
      "Episode 385/1000, Total Reward: 2, Epsilon: 0.145\n",
      "Episode 386/1000, Total Reward: 3, Epsilon: 0.144\n",
      "Episode 387/1000, Total Reward: 1, Epsilon: 0.144\n",
      "Episode 388/1000, Total Reward: 3, Epsilon: 0.143\n",
      "Episode 389/1000, Total Reward: 3, Epsilon: 0.142\n",
      "Episode 390/1000, Total Reward: 2, Epsilon: 0.142\n",
      "Episode 391/1000, Total Reward: 1, Epsilon: 0.141\n",
      "Episode 392/1000, Total Reward: 1, Epsilon: 0.140\n",
      "Episode 393/1000, Total Reward: 3, Epsilon: 0.139\n",
      "Episode 394/1000, Total Reward: 3, Epsilon: 0.139\n",
      "Episode 395/1000, Total Reward: 3, Epsilon: 0.138\n",
      "Episode 396/1000, Total Reward: 3, Epsilon: 0.137\n",
      "Episode 397/1000, Total Reward: 0, Epsilon: 0.137\n",
      "Episode 398/1000, Total Reward: 3, Epsilon: 0.136\n",
      "Episode 399/1000, Total Reward: 1, Epsilon: 0.135\n",
      "Episode 400/1000, Total Reward: -1, Epsilon: 0.135\n",
      "Episode 401/1000, Total Reward: 3, Epsilon: 0.134\n",
      "Episode 402/1000, Total Reward: -4, Epsilon: 0.133\n",
      "Episode 403/1000, Total Reward: 3, Epsilon: 0.133\n",
      "Episode 404/1000, Total Reward: 3, Epsilon: 0.132\n",
      "Episode 405/1000, Total Reward: 2, Epsilon: 0.131\n",
      "Episode 406/1000, Total Reward: -1, Epsilon: 0.131\n",
      "Episode 407/1000, Total Reward: 3, Epsilon: 0.130\n",
      "Episode 408/1000, Total Reward: 2, Epsilon: 0.129\n",
      "Episode 409/1000, Total Reward: 3, Epsilon: 0.129\n",
      "Episode 410/1000, Total Reward: 3, Epsilon: 0.128\n",
      "Episode 411/1000, Total Reward: 1, Epsilon: 0.127\n",
      "Episode 412/1000, Total Reward: 2, Epsilon: 0.127\n",
      "Episode 413/1000, Total Reward: 3, Epsilon: 0.126\n",
      "Episode 414/1000, Total Reward: 2, Epsilon: 0.126\n",
      "Episode 415/1000, Total Reward: 1, Epsilon: 0.125\n",
      "Episode 416/1000, Total Reward: 3, Epsilon: 0.124\n",
      "Episode 417/1000, Total Reward: 3, Epsilon: 0.124\n",
      "Episode 418/1000, Total Reward: 3, Epsilon: 0.123\n",
      "Episode 419/1000, Total Reward: 3, Epsilon: 0.122\n",
      "Episode 420/1000, Total Reward: 2, Epsilon: 0.122\n",
      "Episode 421/1000, Total Reward: 3, Epsilon: 0.121\n",
      "Episode 422/1000, Total Reward: 3, Epsilon: 0.121\n",
      "Episode 423/1000, Total Reward: -3, Epsilon: 0.120\n",
      "Episode 424/1000, Total Reward: 3, Epsilon: 0.119\n",
      "Episode 425/1000, Total Reward: -3, Epsilon: 0.119\n",
      "Episode 426/1000, Total Reward: 1, Epsilon: 0.118\n",
      "Episode 427/1000, Total Reward: 3, Epsilon: 0.118\n",
      "Episode 428/1000, Total Reward: 3, Epsilon: 0.117\n",
      "Episode 429/1000, Total Reward: 3, Epsilon: 0.116\n",
      "Episode 430/1000, Total Reward: 3, Epsilon: 0.116\n",
      "Episode 431/1000, Total Reward: 1, Epsilon: 0.115\n",
      "Episode 432/1000, Total Reward: 3, Epsilon: 0.115\n",
      "Episode 433/1000, Total Reward: 3, Epsilon: 0.114\n",
      "Episode 434/1000, Total Reward: 3, Epsilon: 0.114\n",
      "Episode 435/1000, Total Reward: 3, Epsilon: 0.113\n",
      "Episode 436/1000, Total Reward: 3, Epsilon: 0.112\n",
      "Episode 437/1000, Total Reward: 3, Epsilon: 0.112\n",
      "Episode 438/1000, Total Reward: 0, Epsilon: 0.111\n",
      "Episode 439/1000, Total Reward: 2, Epsilon: 0.111\n",
      "Episode 440/1000, Total Reward: 3, Epsilon: 0.110\n",
      "Episode 441/1000, Total Reward: 1, Epsilon: 0.110\n",
      "Episode 442/1000, Total Reward: 3, Epsilon: 0.109\n",
      "Episode 443/1000, Total Reward: 3, Epsilon: 0.109\n",
      "Episode 444/1000, Total Reward: 1, Epsilon: 0.108\n",
      "Episode 445/1000, Total Reward: 2, Epsilon: 0.107\n",
      "Episode 446/1000, Total Reward: 3, Epsilon: 0.107\n",
      "Episode 447/1000, Total Reward: 1, Epsilon: 0.106\n",
      "Episode 448/1000, Total Reward: 3, Epsilon: 0.106\n",
      "Episode 449/1000, Total Reward: 1, Epsilon: 0.105\n",
      "Episode 450/1000, Total Reward: 1, Epsilon: 0.105\n",
      "Episode 451/1000, Total Reward: -1, Epsilon: 0.104\n",
      "Episode 452/1000, Total Reward: 1, Epsilon: 0.104\n",
      "Episode 453/1000, Total Reward: 3, Epsilon: 0.103\n",
      "Episode 454/1000, Total Reward: 3, Epsilon: 0.103\n",
      "Episode 455/1000, Total Reward: 3, Epsilon: 0.102\n",
      "Episode 456/1000, Total Reward: 3, Epsilon: 0.102\n",
      "Episode 457/1000, Total Reward: 3, Epsilon: 0.101\n",
      "Episode 458/1000, Total Reward: 3, Epsilon: 0.101\n",
      "Episode 459/1000, Total Reward: 1, Epsilon: 0.100\n",
      "Episode 460/1000, Total Reward: -1, Epsilon: 0.100\n",
      "Episode 461/1000, Total Reward: 3, Epsilon: 0.099\n",
      "Episode 462/1000, Total Reward: 3, Epsilon: 0.099\n",
      "Episode 463/1000, Total Reward: 1, Epsilon: 0.098\n",
      "Episode 464/1000, Total Reward: 0, Epsilon: 0.098\n",
      "Episode 465/1000, Total Reward: 2, Epsilon: 0.097\n",
      "Episode 466/1000, Total Reward: 3, Epsilon: 0.097\n",
      "Episode 467/1000, Total Reward: 3, Epsilon: 0.096\n",
      "Episode 468/1000, Total Reward: 3, Epsilon: 0.096\n",
      "Episode 469/1000, Total Reward: 2, Epsilon: 0.095\n",
      "Episode 470/1000, Total Reward: 3, Epsilon: 0.095\n",
      "Episode 471/1000, Total Reward: 1, Epsilon: 0.094\n",
      "Episode 472/1000, Total Reward: 1, Epsilon: 0.094\n",
      "Episode 473/1000, Total Reward: 3, Epsilon: 0.093\n",
      "Episode 474/1000, Total Reward: 1, Epsilon: 0.093\n",
      "Episode 475/1000, Total Reward: 3, Epsilon: 0.092\n",
      "Episode 476/1000, Total Reward: 3, Epsilon: 0.092\n",
      "Episode 477/1000, Total Reward: 3, Epsilon: 0.092\n",
      "Episode 478/1000, Total Reward: 3, Epsilon: 0.091\n",
      "Episode 479/1000, Total Reward: 3, Epsilon: 0.091\n",
      "Episode 480/1000, Total Reward: 1, Epsilon: 0.090\n",
      "Episode 481/1000, Total Reward: 1, Epsilon: 0.090\n",
      "Episode 482/1000, Total Reward: 3, Epsilon: 0.089\n",
      "Episode 483/1000, Total Reward: 3, Epsilon: 0.089\n",
      "Episode 484/1000, Total Reward: 3, Epsilon: 0.088\n",
      "Episode 485/1000, Total Reward: -1, Epsilon: 0.088\n",
      "Episode 486/1000, Total Reward: 3, Epsilon: 0.088\n",
      "Episode 487/1000, Total Reward: 3, Epsilon: 0.087\n",
      "Episode 488/1000, Total Reward: 0, Epsilon: 0.087\n",
      "Episode 489/1000, Total Reward: 3, Epsilon: 0.086\n",
      "Episode 490/1000, Total Reward: 3, Epsilon: 0.086\n",
      "Episode 491/1000, Total Reward: 3, Epsilon: 0.085\n",
      "Episode 492/1000, Total Reward: 1, Epsilon: 0.085\n",
      "Episode 493/1000, Total Reward: 3, Epsilon: 0.084\n",
      "Episode 494/1000, Total Reward: 3, Epsilon: 0.084\n",
      "Episode 495/1000, Total Reward: 3, Epsilon: 0.084\n",
      "Episode 496/1000, Total Reward: 1, Epsilon: 0.083\n",
      "Episode 497/1000, Total Reward: 3, Epsilon: 0.083\n",
      "Episode 498/1000, Total Reward: 3, Epsilon: 0.082\n",
      "Episode 499/1000, Total Reward: 1, Epsilon: 0.082\n",
      "Episode 500/1000, Total Reward: 3, Epsilon: 0.082\n",
      "Episode 501/1000, Total Reward: 1, Epsilon: 0.081\n",
      "Episode 502/1000, Total Reward: 1, Epsilon: 0.081\n",
      "Episode 503/1000, Total Reward: 3, Epsilon: 0.080\n",
      "Episode 504/1000, Total Reward: 3, Epsilon: 0.080\n",
      "Episode 505/1000, Total Reward: 3, Epsilon: 0.080\n",
      "Episode 506/1000, Total Reward: 1, Epsilon: 0.079\n",
      "Episode 507/1000, Total Reward: 3, Epsilon: 0.079\n",
      "Episode 508/1000, Total Reward: 1, Epsilon: 0.078\n",
      "Episode 509/1000, Total Reward: 3, Epsilon: 0.078\n",
      "Episode 510/1000, Total Reward: 3, Epsilon: 0.078\n",
      "Episode 511/1000, Total Reward: 3, Epsilon: 0.077\n",
      "Episode 512/1000, Total Reward: 0, Epsilon: 0.077\n",
      "Episode 513/1000, Total Reward: 1, Epsilon: 0.076\n",
      "Episode 514/1000, Total Reward: 3, Epsilon: 0.076\n",
      "Episode 515/1000, Total Reward: 3, Epsilon: 0.076\n",
      "Episode 516/1000, Total Reward: 3, Epsilon: 0.075\n",
      "Episode 517/1000, Total Reward: 3, Epsilon: 0.075\n",
      "Episode 518/1000, Total Reward: 3, Epsilon: 0.075\n",
      "Episode 519/1000, Total Reward: 2, Epsilon: 0.074\n",
      "Episode 520/1000, Total Reward: 3, Epsilon: 0.074\n",
      "Episode 521/1000, Total Reward: 1, Epsilon: 0.073\n",
      "Episode 522/1000, Total Reward: 3, Epsilon: 0.073\n",
      "Episode 523/1000, Total Reward: 3, Epsilon: 0.073\n",
      "Episode 524/1000, Total Reward: 3, Epsilon: 0.072\n",
      "Episode 525/1000, Total Reward: 3, Epsilon: 0.072\n",
      "Episode 526/1000, Total Reward: 3, Epsilon: 0.072\n",
      "Episode 527/1000, Total Reward: 3, Epsilon: 0.071\n",
      "Episode 528/1000, Total Reward: 3, Epsilon: 0.071\n",
      "Episode 529/1000, Total Reward: 3, Epsilon: 0.071\n",
      "Episode 530/1000, Total Reward: 3, Epsilon: 0.070\n",
      "Episode 531/1000, Total Reward: 3, Epsilon: 0.070\n",
      "Episode 532/1000, Total Reward: 2, Epsilon: 0.069\n",
      "Episode 533/1000, Total Reward: 3, Epsilon: 0.069\n",
      "Episode 534/1000, Total Reward: 3, Epsilon: 0.069\n",
      "Episode 535/1000, Total Reward: 3, Epsilon: 0.068\n",
      "Episode 536/1000, Total Reward: 1, Epsilon: 0.068\n",
      "Episode 537/1000, Total Reward: 1, Epsilon: 0.068\n",
      "Episode 538/1000, Total Reward: 3, Epsilon: 0.067\n",
      "Episode 539/1000, Total Reward: 1, Epsilon: 0.067\n",
      "Episode 540/1000, Total Reward: 3, Epsilon: 0.067\n",
      "Episode 541/1000, Total Reward: 3, Epsilon: 0.066\n",
      "Episode 542/1000, Total Reward: 1, Epsilon: 0.066\n",
      "Episode 543/1000, Total Reward: 3, Epsilon: 0.066\n",
      "Episode 544/1000, Total Reward: 3, Epsilon: 0.065\n",
      "Episode 545/1000, Total Reward: 3, Epsilon: 0.065\n",
      "Episode 546/1000, Total Reward: 3, Epsilon: 0.065\n",
      "Episode 547/1000, Total Reward: 1, Epsilon: 0.064\n",
      "Episode 548/1000, Total Reward: 2, Epsilon: 0.064\n",
      "Episode 549/1000, Total Reward: -1, Epsilon: 0.064\n",
      "Episode 550/1000, Total Reward: 3, Epsilon: 0.063\n",
      "Episode 551/1000, Total Reward: 3, Epsilon: 0.063\n",
      "Episode 552/1000, Total Reward: 1, Epsilon: 0.063\n",
      "Episode 553/1000, Total Reward: 3, Epsilon: 0.063\n",
      "Episode 554/1000, Total Reward: 3, Epsilon: 0.062\n",
      "Episode 555/1000, Total Reward: 3, Epsilon: 0.062\n",
      "Episode 556/1000, Total Reward: 3, Epsilon: 0.062\n",
      "Episode 557/1000, Total Reward: 3, Epsilon: 0.061\n",
      "Episode 558/1000, Total Reward: 3, Epsilon: 0.061\n",
      "Episode 559/1000, Total Reward: 3, Epsilon: 0.061\n",
      "Episode 560/1000, Total Reward: 1, Epsilon: 0.060\n",
      "Episode 561/1000, Total Reward: 1, Epsilon: 0.060\n",
      "Episode 562/1000, Total Reward: 3, Epsilon: 0.060\n",
      "Episode 563/1000, Total Reward: 3, Epsilon: 0.059\n",
      "Episode 564/1000, Total Reward: 3, Epsilon: 0.059\n",
      "Episode 565/1000, Total Reward: 3, Epsilon: 0.059\n",
      "Episode 566/1000, Total Reward: -1, Epsilon: 0.059\n",
      "Episode 567/1000, Total Reward: 3, Epsilon: 0.058\n",
      "Episode 568/1000, Total Reward: 3, Epsilon: 0.058\n",
      "Episode 569/1000, Total Reward: 3, Epsilon: 0.058\n",
      "Episode 570/1000, Total Reward: 3, Epsilon: 0.057\n",
      "Episode 571/1000, Total Reward: 3, Epsilon: 0.057\n",
      "Episode 572/1000, Total Reward: 3, Epsilon: 0.057\n",
      "Episode 573/1000, Total Reward: 2, Epsilon: 0.057\n",
      "Episode 574/1000, Total Reward: 2, Epsilon: 0.056\n",
      "Episode 575/1000, Total Reward: 3, Epsilon: 0.056\n",
      "Episode 576/1000, Total Reward: 1, Epsilon: 0.056\n",
      "Episode 577/1000, Total Reward: 3, Epsilon: 0.055\n",
      "Episode 578/1000, Total Reward: 3, Epsilon: 0.055\n",
      "Episode 579/1000, Total Reward: -1, Epsilon: 0.055\n",
      "Episode 580/1000, Total Reward: 1, Epsilon: 0.055\n",
      "Episode 581/1000, Total Reward: 3, Epsilon: 0.054\n",
      "Episode 582/1000, Total Reward: 3, Epsilon: 0.054\n",
      "Episode 583/1000, Total Reward: 3, Epsilon: 0.054\n",
      "Episode 584/1000, Total Reward: 3, Epsilon: 0.054\n",
      "Episode 585/1000, Total Reward: 2, Epsilon: 0.053\n",
      "Episode 586/1000, Total Reward: 3, Epsilon: 0.053\n",
      "Episode 587/1000, Total Reward: 3, Epsilon: 0.053\n",
      "Episode 588/1000, Total Reward: -1, Epsilon: 0.052\n",
      "Episode 589/1000, Total Reward: 3, Epsilon: 0.052\n",
      "Episode 590/1000, Total Reward: 1, Epsilon: 0.052\n",
      "Episode 591/1000, Total Reward: 3, Epsilon: 0.052\n",
      "Episode 592/1000, Total Reward: 2, Epsilon: 0.051\n",
      "Episode 593/1000, Total Reward: 3, Epsilon: 0.051\n",
      "Episode 594/1000, Total Reward: 3, Epsilon: 0.051\n",
      "Episode 595/1000, Total Reward: 2, Epsilon: 0.051\n",
      "Episode 596/1000, Total Reward: 0, Epsilon: 0.050\n",
      "Episode 597/1000, Total Reward: 3, Epsilon: 0.050\n",
      "Episode 598/1000, Total Reward: 3, Epsilon: 0.050\n",
      "Episode 599/1000, Total Reward: 3, Epsilon: 0.050\n",
      "Episode 600/1000, Total Reward: 3, Epsilon: 0.049\n",
      "Episode 601/1000, Total Reward: 3, Epsilon: 0.049\n",
      "Episode 602/1000, Total Reward: 1, Epsilon: 0.049\n",
      "Episode 603/1000, Total Reward: 3, Epsilon: 0.049\n",
      "Episode 604/1000, Total Reward: 3, Epsilon: 0.048\n",
      "Episode 605/1000, Total Reward: 3, Epsilon: 0.048\n",
      "Episode 606/1000, Total Reward: 3, Epsilon: 0.048\n",
      "Episode 607/1000, Total Reward: 3, Epsilon: 0.048\n",
      "Episode 608/1000, Total Reward: 3, Epsilon: 0.047\n",
      "Episode 609/1000, Total Reward: 3, Epsilon: 0.047\n",
      "Episode 610/1000, Total Reward: 3, Epsilon: 0.047\n",
      "Episode 611/1000, Total Reward: 3, Epsilon: 0.047\n",
      "Episode 612/1000, Total Reward: 3, Epsilon: 0.047\n",
      "Episode 613/1000, Total Reward: 3, Epsilon: 0.046\n",
      "Episode 614/1000, Total Reward: 1, Epsilon: 0.046\n",
      "Episode 615/1000, Total Reward: 3, Epsilon: 0.046\n",
      "Episode 616/1000, Total Reward: 3, Epsilon: 0.046\n",
      "Episode 617/1000, Total Reward: 3, Epsilon: 0.045\n",
      "Episode 618/1000, Total Reward: 3, Epsilon: 0.045\n",
      "Episode 619/1000, Total Reward: 3, Epsilon: 0.045\n",
      "Episode 620/1000, Total Reward: 3, Epsilon: 0.045\n",
      "Episode 621/1000, Total Reward: 3, Epsilon: 0.044\n",
      "Episode 622/1000, Total Reward: 3, Epsilon: 0.044\n",
      "Episode 623/1000, Total Reward: 3, Epsilon: 0.044\n",
      "Episode 624/1000, Total Reward: 3, Epsilon: 0.044\n",
      "Episode 625/1000, Total Reward: 3, Epsilon: 0.044\n",
      "Episode 626/1000, Total Reward: 3, Epsilon: 0.043\n",
      "Episode 627/1000, Total Reward: 3, Epsilon: 0.043\n",
      "Episode 628/1000, Total Reward: 3, Epsilon: 0.043\n",
      "Episode 629/1000, Total Reward: 3, Epsilon: 0.043\n",
      "Episode 630/1000, Total Reward: 3, Epsilon: 0.043\n",
      "Episode 631/1000, Total Reward: 3, Epsilon: 0.042\n",
      "Episode 632/1000, Total Reward: 3, Epsilon: 0.042\n",
      "Episode 633/1000, Total Reward: 3, Epsilon: 0.042\n",
      "Episode 634/1000, Total Reward: 3, Epsilon: 0.042\n",
      "Episode 635/1000, Total Reward: 3, Epsilon: 0.041\n",
      "Episode 636/1000, Total Reward: 3, Epsilon: 0.041\n",
      "Episode 637/1000, Total Reward: 3, Epsilon: 0.041\n",
      "Episode 638/1000, Total Reward: 3, Epsilon: 0.041\n",
      "Episode 639/1000, Total Reward: 3, Epsilon: 0.041\n",
      "Episode 640/1000, Total Reward: 3, Epsilon: 0.040\n",
      "Episode 641/1000, Total Reward: 3, Epsilon: 0.040\n",
      "Episode 642/1000, Total Reward: 3, Epsilon: 0.040\n",
      "Episode 643/1000, Total Reward: 3, Epsilon: 0.040\n",
      "Episode 644/1000, Total Reward: 1, Epsilon: 0.040\n",
      "Episode 645/1000, Total Reward: 2, Epsilon: 0.039\n",
      "Episode 646/1000, Total Reward: 3, Epsilon: 0.039\n",
      "Episode 647/1000, Total Reward: 3, Epsilon: 0.039\n",
      "Episode 648/1000, Total Reward: 1, Epsilon: 0.039\n",
      "Episode 649/1000, Total Reward: 3, Epsilon: 0.039\n",
      "Episode 650/1000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 651/1000, Total Reward: 1, Epsilon: 0.038\n",
      "Episode 652/1000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 653/1000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 654/1000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 655/1000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 656/1000, Total Reward: 3, Epsilon: 0.037\n",
      "Episode 657/1000, Total Reward: 3, Epsilon: 0.037\n",
      "Episode 658/1000, Total Reward: 1, Epsilon: 0.037\n",
      "Episode 659/1000, Total Reward: 3, Epsilon: 0.037\n",
      "Episode 660/1000, Total Reward: 3, Epsilon: 0.037\n",
      "Episode 661/1000, Total Reward: 3, Epsilon: 0.036\n",
      "Episode 662/1000, Total Reward: 3, Epsilon: 0.036\n",
      "Episode 663/1000, Total Reward: 3, Epsilon: 0.036\n",
      "Episode 664/1000, Total Reward: 1, Epsilon: 0.036\n",
      "Episode 665/1000, Total Reward: 1, Epsilon: 0.036\n",
      "Episode 666/1000, Total Reward: 3, Epsilon: 0.035\n",
      "Episode 667/1000, Total Reward: 1, Epsilon: 0.035\n",
      "Episode 668/1000, Total Reward: 3, Epsilon: 0.035\n",
      "Episode 669/1000, Total Reward: 3, Epsilon: 0.035\n",
      "Episode 670/1000, Total Reward: 1, Epsilon: 0.035\n",
      "Episode 671/1000, Total Reward: 3, Epsilon: 0.035\n",
      "Episode 672/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 673/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 674/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 675/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 676/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 677/1000, Total Reward: 3, Epsilon: 0.034\n",
      "Episode 678/1000, Total Reward: 3, Epsilon: 0.033\n",
      "Episode 679/1000, Total Reward: 1, Epsilon: 0.033\n",
      "Episode 680/1000, Total Reward: 3, Epsilon: 0.033\n",
      "Episode 681/1000, Total Reward: 3, Epsilon: 0.033\n",
      "Episode 682/1000, Total Reward: 3, Epsilon: 0.033\n",
      "Episode 683/1000, Total Reward: 1, Epsilon: 0.033\n",
      "Episode 684/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 685/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 686/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 687/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 688/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 689/1000, Total Reward: 3, Epsilon: 0.032\n",
      "Episode 690/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 691/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 692/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 693/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 694/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 695/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 696/1000, Total Reward: 3, Epsilon: 0.031\n",
      "Episode 697/1000, Total Reward: 3, Epsilon: 0.030\n",
      "Episode 698/1000, Total Reward: 3, Epsilon: 0.030\n",
      "Episode 699/1000, Total Reward: 2, Epsilon: 0.030\n",
      "Episode 700/1000, Total Reward: 1, Epsilon: 0.030\n",
      "Episode 701/1000, Total Reward: 1, Epsilon: 0.030\n",
      "Episode 702/1000, Total Reward: 2, Epsilon: 0.030\n",
      "Episode 703/1000, Total Reward: 3, Epsilon: 0.029\n",
      "Episode 704/1000, Total Reward: 3, Epsilon: 0.029\n",
      "Episode 705/1000, Total Reward: 1, Epsilon: 0.029\n",
      "Episode 706/1000, Total Reward: 3, Epsilon: 0.029\n",
      "Episode 707/1000, Total Reward: 1, Epsilon: 0.029\n",
      "Episode 708/1000, Total Reward: 3, Epsilon: 0.029\n",
      "Episode 709/1000, Total Reward: 3, Epsilon: 0.029\n",
      "Episode 710/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 711/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 712/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 713/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 714/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 715/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 716/1000, Total Reward: 3, Epsilon: 0.028\n",
      "Episode 717/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 718/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 719/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 720/1000, Total Reward: 2, Epsilon: 0.027\n",
      "Episode 721/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 722/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 723/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 724/1000, Total Reward: 3, Epsilon: 0.027\n",
      "Episode 725/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 726/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 727/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 728/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 729/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 730/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 731/1000, Total Reward: 3, Epsilon: 0.026\n",
      "Episode 732/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 733/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 734/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 735/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 736/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 737/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 738/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 739/1000, Total Reward: 3, Epsilon: 0.025\n",
      "Episode 740/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 741/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 742/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 743/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 744/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 745/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 746/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 747/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 748/1000, Total Reward: 3, Epsilon: 0.024\n",
      "Episode 749/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 750/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 751/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 752/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 753/1000, Total Reward: 1, Epsilon: 0.023\n",
      "Episode 754/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 755/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 756/1000, Total Reward: 3, Epsilon: 0.023\n",
      "Episode 757/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 758/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 759/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 760/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 761/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 762/1000, Total Reward: 1, Epsilon: 0.022\n",
      "Episode 763/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 764/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 765/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 766/1000, Total Reward: 3, Epsilon: 0.022\n",
      "Episode 767/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 768/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 769/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 770/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 771/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 772/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 773/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 774/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 775/1000, Total Reward: 3, Epsilon: 0.021\n",
      "Episode 776/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 777/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 778/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 779/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 780/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 781/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 782/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 783/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 784/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 785/1000, Total Reward: 3, Epsilon: 0.020\n",
      "Episode 786/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 787/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 788/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 789/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 790/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 791/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 792/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 793/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 794/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 795/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 796/1000, Total Reward: 3, Epsilon: 0.019\n",
      "Episode 797/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 798/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 799/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 800/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 801/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 802/1000, Total Reward: 0, Epsilon: 0.018\n",
      "Episode 803/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 804/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 805/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 806/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 807/1000, Total Reward: 3, Epsilon: 0.018\n",
      "Episode 808/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 809/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 810/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 811/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 812/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 813/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 814/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 815/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 816/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 817/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 818/1000, Total Reward: 3, Epsilon: 0.017\n",
      "Episode 819/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 820/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 821/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 822/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 823/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 824/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 825/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 826/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 827/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 828/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 829/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 830/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 831/1000, Total Reward: 3, Epsilon: 0.016\n",
      "Episode 832/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 833/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 834/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 835/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 836/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 837/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 838/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 839/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 840/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 841/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 842/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 843/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 844/1000, Total Reward: 3, Epsilon: 0.015\n",
      "Episode 845/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 846/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 847/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 848/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 849/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 850/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 851/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 852/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 853/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 854/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 855/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 856/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 857/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 858/1000, Total Reward: 3, Epsilon: 0.014\n",
      "Episode 859/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 860/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 861/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 862/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 863/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 864/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 865/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 866/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 867/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 868/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 869/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 870/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 871/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 872/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 873/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 874/1000, Total Reward: 3, Epsilon: 0.013\n",
      "Episode 875/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 876/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 877/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 878/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 879/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 880/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 881/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 882/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 883/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 884/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 885/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 886/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 887/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 888/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 889/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 890/1000, Total Reward: 3, Epsilon: 0.012\n",
      "Episode 891/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 892/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 893/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 894/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 895/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 896/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 897/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 898/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 899/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 900/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 901/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 902/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 903/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 904/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 905/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 906/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 907/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 908/1000, Total Reward: 3, Epsilon: 0.011\n",
      "Episode 909/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 910/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 911/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 912/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 913/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 914/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 915/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 916/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 917/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 918/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 919/1000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 920/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 921/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 922/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 923/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 924/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 925/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 926/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 927/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 928/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 929/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 930/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 931/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 932/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 933/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 934/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 935/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 936/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 937/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 938/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 939/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 940/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 941/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 942/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 943/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 944/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 945/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 946/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 947/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 948/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 949/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 950/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 951/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 952/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 953/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 954/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 955/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 956/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 957/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 958/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 959/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 960/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 961/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 962/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 963/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 964/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 965/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 966/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 967/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 968/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 969/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 970/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 971/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 972/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 973/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 974/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 975/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 976/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 977/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 978/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 979/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 980/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 981/1000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 982/1000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 983/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 984/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 985/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 986/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 987/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 988/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 989/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 990/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 991/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 992/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 993/1000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 994/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 995/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 996/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 997/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 998/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 999/1000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 1000/1000, Total Reward: 3, Epsilon: 0.010\n",
      "[[-1.4163967  -0.434062   -1.52561672 -0.55010143]\n",
      " [-2.52703448  0.62121926 -2.9101423  -1.30928724]\n",
      " [-1.46736703  1.76695103 -2.86260561 -1.71526663]\n",
      " [-1.80222112  0.65998242 -2.34803275 -1.82011844]\n",
      " [-1.7298786   0.30536656 -1.55011864 -1.67812335]\n",
      " [-1.51815257  0.18806647 -0.51843195  0.62882   ]\n",
      " [-0.77574664  1.76268646 -0.72830364  1.8098    ]\n",
      " [ 0.41994899  3.122       0.58045585  2.53404508]\n",
      " [-1.78416781  4.44234124 -0.41086203  1.6839014 ]\n",
      " [-1.50439835  5.004562   -0.73545128  0.18728279]\n",
      " [-1.83585111 -1.34724944 -1.68649366  1.70197393]\n",
      " [-0.72827102  1.68308454 -1.07059182  3.12189374]\n",
      " [ 1.72236102  4.58        1.72870357  4.52922463]\n",
      " [ 0.92679633  6.19808874  1.50113465  4.73371843]\n",
      " [ 1.22653625  7.89988244  1.96937222  3.6392814 ]\n",
      " [-2.2006532  -1.35558963 -1.69383116  1.35329462]\n",
      " [ 0.25959803  2.14371451 -1.68697865  4.57308614]\n",
      " [ 3.1069141   6.2         3.0623283   6.16612433]\n",
      " [ 3.02034656  7.66635358  3.50378617  7.99999377]\n",
      " [ 5.22365064  9.99999957  5.18642772  7.4978404 ]\n",
      " [-1.64187712 -1.35935714 -1.41385867  2.11133279]\n",
      " [ 0.87784478  1.30891422 -0.72460857  6.19012049]\n",
      " [ 4.56826726  6.16176901  4.51768745  8.        ]\n",
      " [ 6.13078295  7.94714063  6.15273795 10.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_dacay=0.995, min_epsilon=0.01):\n",
    "        self.env = env\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_dacay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.q_table = np.zeros((env.state_space, env.action_space))\n",
    "        self.state = env.reset()\n",
    "\n",
    "    def choose_action(self):\n",
    "        if random.uniform(0,1) < self.epsilon:\n",
    "            return random.randint(0, self.env.action_space - 1)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[self.env.state_to_id(self.state)])\n",
    "    \n",
    "    def update_q_value(self, next_state, action, reward):\n",
    "        current_state_id = self.env.state_to_id(self.state)\n",
    "        next_state_id = self.env.state_to_id(next_state)\n",
    "\n",
    "        best_next_action = np.argmax(self.q_table[next_state_id])\n",
    "        target = reward + self.gamma * self.q_table[next_state_id, best_next_action]\n",
    "        error = target - self.q_table[current_state_id, action] \n",
    "        self.q_table[current_state_id, action] += self.alpha * error\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def train(self, episodes=1000):\n",
    "        for episode in range(episodes):\n",
    "            self.state = self.env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action = self.choose_action()\n",
    "                next_state = self.env.take_action(self.state, action)\n",
    "                reward = self.env.get_reward(next_state)\n",
    "\n",
    "                self.update_q_value(next_state, action, reward)\n",
    "                self.state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                if next_state == self.env.goal_state:\n",
    "                    done = True\n",
    "            \n",
    "            self.update_epsilon()\n",
    "            print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {self.epsilon:.3f}\")\n",
    "        \n",
    "        print(self.q_table)\n",
    "\n",
    "\n",
    "env = GridWorld()\n",
    "agent = Agent(env)\n",
    "\n",
    "agent.train(episodes=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf2362",
   "metadata": {},
   "source": [
    "## **DQN算法**\n",
    "\n",
    "#### **基本内容**\n",
    "\n",
    "DQN是结合Q-learing和深度学习神经网络的强化学习算法，通过神经网络来近似$Q$函数。神经网络接受状态$s_t$作为输入，输出每个可能动作$a_t$的$Q$值。同时使用了下面几种改进技术：\n",
    "\n",
    "1. 经验回放\n",
    "- 在Q-learing中，智能体根据当前状态和动作更新$Q$值，每次更新依赖于当前的状态，导致了样本之间的相关性\n",
    "- 经验回放通过存储智能体的经历(state, action, reward, next_state)，智能体可以随即地从中采样\n",
    "\n",
    "2. 目标网络\n",
    "- Q-learing中，$Q$值更新依赖于最大化下一个状态的$Q$值，$max_{a'}Q(s_{t+1}, a')$\n",
    "- DQN引入了目标网络，是当前$Q$网络的一个副本，目标网络的参数更新慢\n",
    "\n",
    "#### **算法流程**\n",
    "\n",
    "1. 初始化\n",
    "    - 初始化$Q$网络和目标网络，$Q$网络用于估计$Q$值，目标网络用于计算目标$Q$值\n",
    "    - 初始化经验回放缓冲区\n",
    "\n",
    "2. 探索和训练\n",
    "    - 在每个时间步，选择一个动作，使用贪心算法\n",
    "\n",
    "    - 执行动作，获取下一个状态和奖励\n",
    "\n",
    "    - 存储经历到经验回放缓冲区\n",
    "\n",
    "    - 从经验回放缓冲区中随机采样一小批经历\n",
    "\n",
    "    - 使用神经网络和目标网络来计算目标$Q$值，更新$Q$网络的权重\n",
    "\n",
    "3. 更新目标网络\n",
    "    - 每隔一定步数，将$Q$网络的权重复制到目标网络中\n",
    "    - 进行重复训练迭代\n",
    "\n",
    "#### **核心原理**\n",
    "\n",
    "假设用$Q(s,a;\\theta)$表示$Q$网络，其中$\\theta$是$Q$网络的参数，希望最小化损失函数：\n",
    "\n",
    "$$L(\\theta) = \\mathbb{E}_{(s_t, a_t, r_t, s_{t+1}) \\sim \\mathcal{D}} \\left[ \\left( r_{t+1} + \\gamma \\max_{a'} Q(s_{t+1}, a'; \\theta^-) - Q(s_t, a_t; \\theta) \\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $Q(s_t, a_t; \\theta)$是当前$Q$网络的$Q$值\n",
    "- $Q(s_{t+1}, a'; \\theta^-)$是目标网络的$Q$值\n",
    "- $D$是经验回放池\n",
    "\n",
    "训练过程中，神经网络通过优化损失函数$L(\\theta)$来更新网络的参数$\\theta$，从而使得$Q$网络的输出尽可能接近期望的目标$Q$值。损失函数的最小化使用反向传播算法完成，计算损失函数的梯度并利用梯度下降更新参数，同时损失函数中利用了$\\mathbb{E}$期望，表示计算目标时要从经验回放池中随机采样一批经历\n",
    "\n",
    "#### **DQN示例**\n",
    "\n",
    "\n",
    "针对环境**CartPole-v1**实现一个DQN算法，利用深度$Q$网络学习最优策略。**CartPole-v1**任务为agent控制小车的左右运动，使杆子竖直不倒下。每一个回合`max_step=500`，杆子倒下或者超过最大步数，回合结束。agent在每一个回合内的目标是保持杆子尽可能长的时间\n",
    "\n",
    "1. 状态空间：\n",
    "    - x：推车的位置\n",
    "    - x_dot：推车的速度\n",
    "    - theta：杆子的角度\n",
    "    - theta_dot：杆子的角速度\n",
    "2. 动作空间：\n",
    "    - 0：推车向左移动\n",
    "    - 1：推车向右移动\n",
    "3. 奖励：\n",
    "    - agent每一步成功使杆子不倒下，reward+1\n",
    "    - 当杆子倒下或推车移出界限时，回合结束，奖励为$0$，环境进入结束状态\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56baf036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\transformer\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "C:\\Users\\31453\\AppData\\Local\\Temp\\ipykernel_24744\\2581028744.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  states = torch.tensor(states, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/1000, Total Reward: 36.0, Epsilon: 1.000\n",
      "Episode 11/1000, Total Reward: 11.0, Epsilon: 0.545\n",
      "Episode 21/1000, Total Reward: 9.0, Epsilon: 0.294\n",
      "Episode 31/1000, Total Reward: 8.0, Epsilon: 0.171\n",
      "Episode 41/1000, Total Reward: 34.0, Epsilon: 0.075\n",
      "Episode 51/1000, Total Reward: 46.0, Epsilon: 0.015\n",
      "Episode 61/1000, Total Reward: 167.0, Epsilon: 0.010\n",
      "Episode 71/1000, Total Reward: 389.0, Epsilon: 0.010\n",
      "Episode 81/1000, Total Reward: 179.0, Epsilon: 0.010\n",
      "Episode 91/1000, Total Reward: 297.0, Epsilon: 0.010\n",
      "Episode 101/1000, Total Reward: 442.0, Epsilon: 0.010\n",
      "Episode 111/1000, Total Reward: 151.0, Epsilon: 0.010\n",
      "Episode 121/1000, Total Reward: 154.0, Epsilon: 0.010\n",
      "Episode 131/1000, Total Reward: 232.0, Epsilon: 0.010\n",
      "Episode 141/1000, Total Reward: 250.0, Epsilon: 0.010\n",
      "Episode 151/1000, Total Reward: 159.0, Epsilon: 0.010\n",
      "Episode 161/1000, Total Reward: 165.0, Epsilon: 0.010\n",
      "Episode 171/1000, Total Reward: 144.0, Epsilon: 0.010\n",
      "Episode 181/1000, Total Reward: 128.0, Epsilon: 0.010\n",
      "Episode 191/1000, Total Reward: 130.0, Epsilon: 0.010\n",
      "Episode 201/1000, Total Reward: 38.0, Epsilon: 0.010\n",
      "Episode 211/1000, Total Reward: 154.0, Epsilon: 0.010\n",
      "Episode 221/1000, Total Reward: 137.0, Epsilon: 0.010\n",
      "Episode 231/1000, Total Reward: 135.0, Epsilon: 0.010\n",
      "Episode 241/1000, Total Reward: 131.0, Epsilon: 0.010\n",
      "Episode 251/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 261/1000, Total Reward: 127.0, Epsilon: 0.010\n",
      "Episode 271/1000, Total Reward: 113.0, Epsilon: 0.010\n",
      "Episode 281/1000, Total Reward: 125.0, Epsilon: 0.010\n",
      "Episode 291/1000, Total Reward: 132.0, Epsilon: 0.010\n",
      "Episode 301/1000, Total Reward: 128.0, Epsilon: 0.010\n",
      "Episode 311/1000, Total Reward: 123.0, Epsilon: 0.010\n",
      "Episode 321/1000, Total Reward: 128.0, Epsilon: 0.010\n",
      "Episode 331/1000, Total Reward: 138.0, Epsilon: 0.010\n",
      "Episode 341/1000, Total Reward: 122.0, Epsilon: 0.010\n",
      "Episode 351/1000, Total Reward: 204.0, Epsilon: 0.010\n",
      "Episode 361/1000, Total Reward: 244.0, Epsilon: 0.010\n",
      "Episode 371/1000, Total Reward: 149.0, Epsilon: 0.010\n",
      "Episode 381/1000, Total Reward: 261.0, Epsilon: 0.010\n",
      "Episode 391/1000, Total Reward: 143.0, Epsilon: 0.010\n",
      "Episode 401/1000, Total Reward: 213.0, Epsilon: 0.010\n",
      "Episode 411/1000, Total Reward: 175.0, Epsilon: 0.010\n",
      "Episode 421/1000, Total Reward: 122.0, Epsilon: 0.010\n",
      "Episode 431/1000, Total Reward: 174.0, Epsilon: 0.010\n",
      "Episode 441/1000, Total Reward: 169.0, Epsilon: 0.010\n",
      "Episode 451/1000, Total Reward: 141.0, Epsilon: 0.010\n",
      "Episode 461/1000, Total Reward: 124.0, Epsilon: 0.010\n",
      "Episode 471/1000, Total Reward: 124.0, Epsilon: 0.010\n",
      "Episode 481/1000, Total Reward: 141.0, Epsilon: 0.010\n",
      "Episode 491/1000, Total Reward: 113.0, Epsilon: 0.010\n",
      "Episode 501/1000, Total Reward: 120.0, Epsilon: 0.010\n",
      "Episode 511/1000, Total Reward: 48.0, Epsilon: 0.010\n",
      "Episode 521/1000, Total Reward: 160.0, Epsilon: 0.010\n",
      "Episode 531/1000, Total Reward: 134.0, Epsilon: 0.010\n",
      "Episode 541/1000, Total Reward: 133.0, Epsilon: 0.010\n",
      "Episode 551/1000, Total Reward: 128.0, Epsilon: 0.010\n",
      "Episode 561/1000, Total Reward: 133.0, Epsilon: 0.010\n",
      "Episode 571/1000, Total Reward: 120.0, Epsilon: 0.010\n",
      "Episode 581/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 591/1000, Total Reward: 116.0, Epsilon: 0.010\n",
      "Episode 601/1000, Total Reward: 120.0, Epsilon: 0.010\n",
      "Episode 611/1000, Total Reward: 121.0, Epsilon: 0.010\n",
      "Episode 621/1000, Total Reward: 12.0, Epsilon: 0.010\n",
      "Episode 631/1000, Total Reward: 106.0, Epsilon: 0.010\n",
      "Episode 641/1000, Total Reward: 109.0, Epsilon: 0.010\n",
      "Episode 651/1000, Total Reward: 107.0, Epsilon: 0.010\n",
      "Episode 661/1000, Total Reward: 46.0, Epsilon: 0.010\n",
      "Episode 671/1000, Total Reward: 106.0, Epsilon: 0.010\n",
      "Episode 681/1000, Total Reward: 110.0, Epsilon: 0.010\n",
      "Episode 691/1000, Total Reward: 312.0, Epsilon: 0.010\n",
      "Episode 701/1000, Total Reward: 122.0, Epsilon: 0.010\n",
      "Episode 711/1000, Total Reward: 111.0, Epsilon: 0.010\n",
      "Episode 721/1000, Total Reward: 111.0, Epsilon: 0.010\n",
      "Episode 731/1000, Total Reward: 110.0, Epsilon: 0.010\n",
      "Episode 741/1000, Total Reward: 119.0, Epsilon: 0.010\n",
      "Episode 751/1000, Total Reward: 114.0, Epsilon: 0.010\n",
      "Episode 761/1000, Total Reward: 111.0, Epsilon: 0.010\n",
      "Episode 771/1000, Total Reward: 116.0, Epsilon: 0.010\n",
      "Episode 781/1000, Total Reward: 120.0, Epsilon: 0.010\n",
      "Episode 791/1000, Total Reward: 124.0, Epsilon: 0.010\n",
      "Episode 801/1000, Total Reward: 126.0, Epsilon: 0.010\n",
      "Episode 811/1000, Total Reward: 117.0, Epsilon: 0.010\n",
      "Episode 821/1000, Total Reward: 122.0, Epsilon: 0.010\n",
      "Episode 831/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 841/1000, Total Reward: 106.0, Epsilon: 0.010\n",
      "Episode 851/1000, Total Reward: 116.0, Epsilon: 0.010\n",
      "Episode 861/1000, Total Reward: 124.0, Epsilon: 0.010\n",
      "Episode 871/1000, Total Reward: 117.0, Epsilon: 0.010\n",
      "Episode 881/1000, Total Reward: 121.0, Epsilon: 0.010\n",
      "Episode 891/1000, Total Reward: 115.0, Epsilon: 0.010\n",
      "Episode 901/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 911/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 921/1000, Total Reward: 118.0, Epsilon: 0.010\n",
      "Episode 931/1000, Total Reward: 121.0, Epsilon: 0.010\n",
      "Episode 941/1000, Total Reward: 115.0, Epsilon: 0.010\n",
      "Episode 951/1000, Total Reward: 114.0, Epsilon: 0.010\n",
      "Episode 961/1000, Total Reward: 122.0, Epsilon: 0.010\n",
      "Episode 971/1000, Total Reward: 123.0, Epsilon: 0.010\n",
      "Episode 981/1000, Total Reward: 121.0, Epsilon: 0.010\n",
      "Episode 991/1000, Total Reward: 123.0, Epsilon: 0.010\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# env = gym.make('CartPole-v1')\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, env, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01, alpha=0.001, batch_size=64, memory_size=10000):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = device\n",
    "\n",
    "        # 当前Q网络与目标Q网络\n",
    "        self.q_network = QNetwork(env.observation_space.shape[0], env.action_space.n)\n",
    "        self.target_network = QNetwork(env.observation_space.shape[0], env.action_space.n)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=alpha)\n",
    "        self.update_target_network()\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        \n",
    "        state = np.array(state)\n",
    "        state = torch.tensor(state, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        q_values = self.q_network(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "    \n",
    "    def store_experience(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        return random.sample(self.memory, self.batch_size)\n",
    "    \n",
    "    def train(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = self.sample_batch()\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = np.array(states)\n",
    "        next_states = np.array(next_states)\n",
    "\n",
    "        states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(self.device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(self.device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32).to(self.device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # 计算当前Q网络输出的Q值\n",
    "        q_values = self.q_network(states).gather(1, actions.view(-1, 1)).squeeze(1)\n",
    "\n",
    "        # 计算目标Q网络的输出Q值\n",
    "        next_q_values = self.target_network(next_states).max(1)[0]\n",
    "        target_q_values = rewards + self.gamma * next_q_values * (1 - dones)\n",
    "\n",
    "        # Loss\n",
    "        loss = nn.MSELoss()(q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "def train_dqn(episodes=1000):\n",
    "    env = gym.make('CartPole-v1')\n",
    "    agent = DQNAgent(env)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state, info = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            agent.store_experience(state, action, reward, next_state, done)\n",
    "            agent.train()\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            agent.update_target_network()\n",
    "            print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.3f}\")\n",
    "        \n",
    "train_dqn(1000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
